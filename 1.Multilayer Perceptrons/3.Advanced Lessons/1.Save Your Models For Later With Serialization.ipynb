{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Deep-Learning-Challenge/challenge-notebooks/blob/master/1.Multilayer%20Perceptrons/3.Advanced%20Lessons/1.Save%20Your%20Models%20For%20Later%20With%20Serialization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Your Models For Later With Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that deep learning models can take hours, days, and even weeks to train, it is important to know how to save and load them from disk. In this lesson, you will discover how you can save your Keras models to file and load them up again to make predictions. After completing this lesson, you will know:\n",
    "\n",
    "* How to save and load Keras model weights to HDF5 formatted files.\n",
    "* How to save and load the Keras model structure to JSON files.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../datasets/pima-indians-diabetes.data.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "dataset_name = \"pima-indians-diabetes.data.csv\"\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATASET = f\"https://github.com/Deep-Learning-Challenge/challenge-notebooks/raw/master/datasets/{dataset_name}\"\n",
    "else:\n",
    "    DATASET = f\"../../datasets/{dataset_name}\"\n",
    "    \n",
    "DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras separates the concerns of saving your model architecture and saving your model weights. Model weights are saved to HDF5 format. This is a grid format that is ideal for storing multi-dimensional arrays of numbers. The model structure can be described and saved (and loaded) using two different formats: JSON and YAML.\n",
    "\n",
    "Each example will also demonstrate saving and loading your model weights to HDF5 formatted files. The examples will use the same simple network trained on the Pima Indians the onset of diabetes binary classification dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hierarchical Data Format, or HDF5 for short, is a flexible data storage format and is convenient for storing large arrays of real values, as we have in the weights of neural networks. You may need to install Python support for the HDF5 file format. You can do this using your preferred Python package management system such as Pip:\n",
    "\n",
    "`sudo pip install h5py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Your Neural Network Model to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON is a simple file format for describing data hierarchically. Keras provides the ability to describe any model using JSON format with a `to_json()` function. This can be saved to file and later loaded via the `model_from_json()` function that will create a new model from the JSON specification.\n",
    "\n",
    "The weights are saved directly from the model using the `save_weights()` function and later loaded using the symmetrical `load_weights()` function. The example below trains and evaluates a simple model on the Pima Indians dataset. The model structure is then converted to JSON format and written to `model.json` in the local directory. The network weights are written to `model.h5` in the local directory.\n",
    "\n",
    "The model and weight data are loaded from the saved files, and a new model is created. It is important to compile the loaded model before it is used. This is so that the model's predictions can use the appropriate, efficient computation from the Keras backend. The model is evaluated in the same way printing the same evaluation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 09:50:30.776194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-17 09:50:30.776430: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-10-17 09:50:40.683507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-17 09:50:40.683622: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-17 09:50:40.683683: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (33d7dde1ac92): /proc/driver/nvidia/version does not exist\n",
      "2021-10-17 09:50:40.684224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-17 09:50:41.733239: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 79.17%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(DATASET, delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load json and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 79.17%\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile( metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON format of the model looks like the following:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "  \"class_name\":\"Sequential\",\n",
    "  \"config\":{\n",
    "    \"name\":\"sequential\",\n",
    "    \"layers\":[\n",
    "      {\n",
    "        \"class_name\":\"InputLayer\",\n",
    "        \"config\":{\n",
    "          \"batch_input_shape\":[\n",
    "            null,\n",
    "            8\n",
    "          ],\n",
    "          \"dtype\":\"float32\",\n",
    "          \"sparse\":false,\n",
    "          \"ragged\":false,\n",
    "          \"name\":\"dense_input\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"class_name\":\"Dense\",\n",
    "        \"config\":{\n",
    "          \"name\":\"dense\",\n",
    "          \"trainable\":true,\n",
    "          \"batch_input_shape\":[\n",
    "            null,\n",
    "            8\n",
    "          ],\n",
    "          \"dtype\":\"float32\",\n",
    "          \"units\":12,\n",
    "          \"activation\":\"relu\",\n",
    "          \"use_bias\":true,\n",
    "          \"kernel_initializer\":{\n",
    "            \"class_name\":\"RandomUniform\",\n",
    "            \"config\":{\n",
    "              \"minval\":-0.05,\n",
    "              \"maxval\":0.05,\n",
    "              \"seed\":null\n",
    "            }\n",
    "          },\n",
    "          \"bias_initializer\":{\n",
    "            \"class_name\":\"Zeros\",\n",
    "            \"config\":{\n",
    "\n",
    "            }\n",
    "          },\n",
    "          \"kernel_regularizer\":null,\n",
    "          \"bias_regularizer\":null,\n",
    "          \"activity_regularizer\":null,\n",
    "          \"kernel_constraint\":null,\n",
    "          \"bias_constraint\":null\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"class_name\":\"Dense\",\n",
    "        \"config\":{\n",
    "          \"name\":\"dense_1\",\n",
    "          \"trainable\":true,\n",
    "          \"dtype\":\"float32\",\n",
    "          \"units\":8,\n",
    "          \"activation\":\"relu\",\n",
    "          \"use_bias\":true,\n",
    "          \"kernel_initializer\":{\n",
    "            \"class_name\":\"RandomUniform\",\n",
    "            \"config\":{\n",
    "              \"minval\":-0.05,\n",
    "              \"maxval\":0.05,\n",
    "              \"seed\":null\n",
    "            }\n",
    "          },\n",
    "          \"bias_initializer\":{\n",
    "            \"class_name\":\"Zeros\",\n",
    "            \"config\":{\n",
    "\n",
    "            }\n",
    "          },\n",
    "          \"kernel_regularizer\":null,\n",
    "          \"bias_regularizer\":null,\n",
    "          \"activity_regularizer\":null,\n",
    "          \"kernel_constraint\":null,\n",
    "          \"bias_constraint\":null\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"class_name\":\"Dense\",\n",
    "        \"config\":{\n",
    "          \"name\":\"dense_2\",\n",
    "          \"trainable\":true,\n",
    "          \"dtype\":\"float32\",\n",
    "          \"units\":1,\n",
    "          \"activation\":\"sigmoid\",\n",
    "          \"use_bias\":true,\n",
    "          \"kernel_initializer\":{\n",
    "            \"class_name\":\"RandomUniform\",\n",
    "            \"config\":{\n",
    "              \"minval\":-0.05,\n",
    "              \"maxval\":0.05,\n",
    "              \"seed\":null\n",
    "            }\n",
    "          },\n",
    "          \"bias_initializer\":{\n",
    "            \"class_name\":\"Zeros\",\n",
    "            \"config\":{\n",
    "\n",
    "            }\n",
    "          },\n",
    "          \"kernel_regularizer\":null,\n",
    "          \"bias_regularizer\":null,\n",
    "          \"activity_regularizer\":null,\n",
    "          \"kernel_constraint\":null,\n",
    "          \"bias_constraint\":null\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"keras_version\":\"2.4.0\",\n",
    "  \"backend\":\"tensorflow\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading models is an important capability for transplanting a deep learning model from research and development to operations. In this lesson, you discovered how to serialize your Keras deep learning models. You learned:\n",
    "\n",
    "* How to save model weights to HDF5 formatted files and load them again later.\n",
    "* How to save Keras model definitions to JSON files and load them again."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
