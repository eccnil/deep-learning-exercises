{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Deep-Learning-Challenge/challenge-notebooks/blob/master/2.Convolutional%20Neural%20Networks/2.Guided%20Projects/2.Object%20Recognition%20in%20Photographs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition in Photographs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A difficult problem where traditional neural networks fall is called object recognition. It is where a model can identify objects in images. This lesson will discover how to develop and evaluate deep learning models for object recognition in Keras. After completing this step-by-step tutorial, you will know:\n",
    "\n",
    "* About the CIFAR-10 object recognition dataset and how to load and use it in Keras.\n",
    "* How to create a simple Convolutional Neural Network for object recognition.\n",
    "* How to lift performance by creating deeper Convolutional Neural Networks.\n",
    "\n",
    "Let's get started.\n",
    "\n",
    "**Note**: You may want to speed up the computation for this tutorial by using GPU rather than CPU hardware. This is a suggestion, not a requirement. The tutorial will work just fine on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photograph Object Recognition Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of automatically identifying objects in photographs is difficult because of the near-infinite number of permutations of objects, positions, lighting, etc. It's a tough problem. This is a well-studied problem in computer vision and, more recently, an important demonstration of deep learning capability. The Canadian Institute for Advanced Research developed a standard computer vision and deep learning dataset for this problem (CIFAR).\n",
    "\n",
    "The [CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of 60,000 photos divided into ten classes (hence the name CIFAR-10). Classes include common objects such as airplanes, automobiles, birds, cats, and so on. The dataset is split in a standard way, where 50,000 images are used for training a model and the remaining 10,000 for evaluating its performance. The photos are in color with red, green, and blue channels but are small, measuring 32 x 32-pixel squares.\n",
    "\n",
    "The CIFAR-10 dataset consists of 60,000 photos divided into ten classes (hence the name CIFAR-10)1. Classes include common objects such as airplanes, automobiles, birds, cats, and so on. The dataset is split in a standard way, where 50,000 images are used for training a model and the remaining 10,000 for evaluating its performance. The photos are in color with red, green, and blue channels but are small, measuring 32 x 32-pixel squares.\n",
    "\n",
    "State-of-the-art results can be achieved using very large convolutional neural networks. You can learn about state-of-the-art results on CIFAR-10 on Rodrigo Benenson's [webpage](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). Model performance is reported in classification accuracy, with very good performance above 90% with human performance on the problem at 94% and state-of-the-art results at 96% at the time of writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The CIFAR-10 Dataset in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset can easily be loaded in Keras. Keras has the facility to automatically download standard datasets like CIFAR-10 and store them in the `~/.keras/datasets` directory using the `cifar10.load_data()` function. This dataset is large at 163 megabytes, so it may take a few minutes to download. Once downloaded, subsequent calls to the function will load the dataset ready for use. \n",
    "\n",
    "The dataset is stored as Python pickled training and test sets, ready for use in Keras. Each image is represented as a three-dimensional matrix, with dimensions for red, green, blue, width, and height. We can plot images directly using the Matplotlib Python plotting library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "In FT2Font: Can not load face (error code 0x55)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m                        else suppress())\n\u001b[0;32m   2229\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2230\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2789\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2790\u001b[1;33m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   2791\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[0;32m   2792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                 **kwargs)\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2919\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2921\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2923\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0m\u001b[0;32m   1143\u001b[0m                                                                 renderer)\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1069\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1070\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1069\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1070\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m             \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# Full vertical extent of font, including ascenders and descenders:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;34m\"lp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             ismath=\"TeX\" if self.get_usetex() else False)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# width and height of unrotated string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[1;34m(self, prop)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m    273\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[1;34m(filename, hinting_factor)\u001b[0m\n\u001b[0;32m   1422\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.hinting_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m     \u001b[1;31m# also key on the thread ID to prevent segfaults with multi-threading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m     return _get_font(filename, hinting_factor,\n\u001b[0m\u001b[0;32m   1425\u001b[0m                      \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.kerning_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m                      thread_id=threading.get_ident())\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m_get_font\u001b[1;34m(filename, hinting_factor, _kerning_factor, thread_id)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinting_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1405\u001b[1;33m     return ft2font.FT2Font(\n\u001b[0m\u001b[0;32m   1406\u001b[0m         filename, hinting_factor, _kerning_factor=_kerning_factor)\n\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: In FT2Font: Can not load face (error code 0x55)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Plot ad hoc CIFAR10 instances\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "# from scipy.misc import toimage\n",
    "from PIL import Image\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# create a grid of 3x3 images\n",
    "for i in range(0, 9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(Image.fromarray(X_train[i]))\n",
    "\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code, create a 3 x 3 plot of photographs. The images have been scaled up from their small 32 x 32 sizes, but you can see trucks, horses, and cars. You can also see some distortion in the images that have been forced to the square aspect ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN for CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 problem is best solved using a convolutional neural network (CNN). We can quickly start by importing all of the classes and functions we will need in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "#for windows\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1000)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is good practice, we next initialize the random number seed with a constant to ensure the results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can load the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values range from 0 to 255 for each of the red, green, and blue channels. It is good practice to work with normalized data. Because the input values are well understood, we can easily normalize to the range 0 to 1 by dividing each value by the maximum observation, 255. Note, the data is loaded as integers, so we must cast it to float point values to perform the division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variables are defined as a vector of integers from 0 to 1 for each class. We can use one-hot encoding to transform them into a binary matrix to best model the classification problem. We know there are ten classes for this problem so that we can expect the binary matrix to have a width of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a simple CNN structure as a baseline and evaluate how well it performs on the problem. We will use a structure with two convolutional layers followed by max-pooling and a flattening out of the network to fully connected layers to make predictions. Our baseline network structure can be summarized as follows:\n",
    "\n",
    "1. Convolutional input layer, 32 feature maps with a size of 3 \u0002 3, a rectifier activation function, and a weight constraint of max norm set to 3.\n",
    "2. Dropout set to 20%.\n",
    "3. Convolutional layer, 32 feature maps with a size of 3 x 3, a rectifier activation function, and a weight constraint of max norm set to 3.\n",
    "4. Max Pool layer with the size 2 x 2.\n",
    "5. Flatten layer.\n",
    "6. Fully connected layer with 512 units and a rectifier activation function.\n",
    "7. Dropout set to 50%.\n",
    "8. Fully connected output layer with ten units and a softmax activation function.\n",
    "\n",
    "A logarithmic loss function is used with the stochastic gradient descent optimization algorithm configured with a large momentum and weight decay, starting with a learning rate of 0.01. A visualization of the network structure is provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Summary of the Convolutional Neural Network Structure](../../images/summary_cnn_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,210,090\n",
      "Trainable params: 4,210,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eccni_000\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu',kernel_constraint=MaxNorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=MaxNorm(3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit this model with 25 epochs and a batch size of 32. A small number of epochs was chosen to help keep this tutorial moving. Normally, the number of epochs would be one or two orders of magnitude larger for this problem. Once the model is fit, we evaluate it on the test dataset and print out the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1563 [==============================] - 53s 31ms/step - loss: 1.7099 - accuracy: 0.3841 - val_loss: 1.4023 - val_accuracy: 0.4956\n",
      "Epoch 2/25\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 1.3650 - accuracy: 0.5086 - val_loss: 1.2107 - val_accuracy: 0.5688\n",
      "Epoch 3/25\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 1.2138 - accuracy: 0.5649 - val_loss: 1.1272 - val_accuracy: 0.5929\n",
      "Epoch 4/25\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 1.1024 - accuracy: 0.6053 - val_loss: 1.0876 - val_accuracy: 0.6095\n",
      "Epoch 5/25\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 1.0198 - accuracy: 0.6360 - val_loss: 1.0222 - val_accuracy: 0.6357\n",
      "Epoch 6/25\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.9395 - accuracy: 0.6660 - val_loss: 0.9982 - val_accuracy: 0.6488\n",
      "Epoch 7/25\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 0.8673 - accuracy: 0.6935 - val_loss: 0.9660 - val_accuracy: 0.6590\n",
      "Epoch 8/25\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.8108 - accuracy: 0.7110 - val_loss: 0.9551 - val_accuracy: 0.6634\n",
      "Epoch 9/25\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7509 - accuracy: 0.7336 - val_loss: 0.9424 - val_accuracy: 0.6708\n",
      "Epoch 10/25\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.6999 - accuracy: 0.7537 - val_loss: 0.9370 - val_accuracy: 0.6717\n",
      "Epoch 11/25\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.6556 - accuracy: 0.7692 - val_loss: 0.9368 - val_accuracy: 0.6728\n",
      "Epoch 12/25\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.6070 - accuracy: 0.7865 - val_loss: 0.9453 - val_accuracy: 0.6798\n",
      "Epoch 13/25\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5760 - accuracy: 0.7967 - val_loss: 0.9368 - val_accuracy: 0.6855\n",
      "Epoch 14/25\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5364 - accuracy: 0.8083 - val_loss: 0.9434 - val_accuracy: 0.6842\n",
      "Epoch 15/25\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.5043 - accuracy: 0.8222 - val_loss: 0.9514 - val_accuracy: 0.6889\n",
      "Epoch 16/25\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4718 - accuracy: 0.8340 - val_loss: 0.9654 - val_accuracy: 0.6833\n",
      "Epoch 17/25\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.4492 - accuracy: 0.8421 - val_loss: 0.9656 - val_accuracy: 0.6888\n",
      "Epoch 18/25\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.4221 - accuracy: 0.8499 - val_loss: 0.9788 - val_accuracy: 0.6934\n",
      "Epoch 19/25\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.4014 - accuracy: 0.8573 - val_loss: 0.9791 - val_accuracy: 0.6932\n",
      "Epoch 20/25\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.3773 - accuracy: 0.8655 - val_loss: 1.0199 - val_accuracy: 0.6887\n",
      "Epoch 21/25\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.3619 - accuracy: 0.8736 - val_loss: 0.9969 - val_accuracy: 0.6928\n",
      "Epoch 22/25\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.3426 - accuracy: 0.8793 - val_loss: 1.0186 - val_accuracy: 0.6897\n",
      "Epoch 23/25\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.3307 - accuracy: 0.8841 - val_loss: 1.0267 - val_accuracy: 0.6914\n",
      "Epoch 24/25\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.3151 - accuracy: 0.8899 - val_loss: 1.0243 - val_accuracy: 0.6940\n",
      "Epoch 25/25\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2968 - accuracy: 0.8964 - val_loss: 1.0403 - val_accuracy: 0.6950\n",
      "Accuracy: 69.50%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy and loss are printed each epoch on both the training and test datasets. The model is evaluated on the test set and achieves an accuracy of 69.77%, which is good but not excellent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the accuracy significantly by creating a much deeper network. This is what we will look at in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger CNN for CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that a simple CNN performs poorly on this complex problem. In this section, we look at scaling up the size and complexity of our model. Let's design a deep version of the simple CNN above. We can introduce an additional round of convolutions with many more feature maps. We will use the same pattern of Convolutional, Dropout, Convolutional, and Max Pooling layers.\n",
    "\n",
    "This pattern will be repeated three times with 32, 64, and 128 feature maps. The effect will be an increasing number of feature maps with a smaller and smaller size given the max-pooling layers. Finally, an additional and larger Dense layer will be used at the network's output end to translate better the large number feature maps to class values. We can summarize a new network architecture as follows:\n",
    "\n",
    "1. A convolutional input layer, 32 feature maps with a size of 3 x 3, and a rectifier activation function.\n",
    "2. Dropout layer at 20%.\n",
    "3. Convolutional layer, 32 feature maps with a size of 3 x 3, and a rectifier activation function.\n",
    "4. Max Pool layer with size 2 x 2.\n",
    "5. Convolutional layer, 64 feature maps with a size of 3 x 3, and a rectifier activation function.\n",
    "6. Dropout layer at 20%.\n",
    "7. Convolutional layer, 64 feature maps with a size of 3 x 3, and a rectifier activation function.\n",
    "8. Max Pool layer with size 2 x 2.\n",
    "9. Convolutional layer, 128 feature maps with a size of 3 x 3, and a rectifier activation function.\n",
    "10. Dropout layer at 20%.\n",
    "11. Convolutional layer, 128 feature maps with a size of 3 x 3, and a rectifier activation function.\n",
    "12. Max Pool layer with size 2 x 2.\n",
    "13. Flatten layer.\n",
    "14. Dropout layer at 20%.\n",
    "15. Fully connected layer with 1,024 units and a rectifier activation function.\n",
    "16. Dropout layer at 20%.\n",
    "17. Fully connected layer with 512 units and a  rectifier activation function.\n",
    "18. Dropout layer at 20%.\n",
    "19. Fully connected output layer with ten units and a softmax activation function.\n",
    "\n",
    "This is a larger network and a bit unwieldy to visualize. We can fit and evaluate this model using the same procedure above and the same number of epochs but a larger batch size of 64, found through some minor experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,915,114\n",
      "Trainable params: 2,915,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "782/782 [==============================] - 35s 42ms/step - loss: 1.8888 - accuracy: 0.3048 - val_loss: 1.5485 - val_accuracy: 0.4466\n",
      "Epoch 2/25\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 1.4941 - accuracy: 0.4564 - val_loss: 1.5010 - val_accuracy: 0.4765\n",
      "Epoch 3/25\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 1.3239 - accuracy: 0.5206 - val_loss: 1.2440 - val_accuracy: 0.5518\n",
      "Epoch 4/25\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 1.2001 - accuracy: 0.5676 - val_loss: 1.1538 - val_accuracy: 0.5856\n",
      "Epoch 5/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 1.0982 - accuracy: 0.6038 - val_loss: 1.0607 - val_accuracy: 0.6160\n",
      "Epoch 6/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 1.0123 - accuracy: 0.6392 - val_loss: 0.9563 - val_accuracy: 0.6611\n",
      "Epoch 7/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.9359 - accuracy: 0.6660 - val_loss: 0.9007 - val_accuracy: 0.6829\n",
      "Epoch 8/25\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.8768 - accuracy: 0.6898 - val_loss: 0.8526 - val_accuracy: 0.7026\n",
      "Epoch 9/25\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.8220 - accuracy: 0.7093 - val_loss: 0.8303 - val_accuracy: 0.7096\n",
      "Epoch 10/25\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.7789 - accuracy: 0.7240 - val_loss: 0.7785 - val_accuracy: 0.7289\n",
      "Epoch 11/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.7342 - accuracy: 0.7398 - val_loss: 0.7534 - val_accuracy: 0.7412\n",
      "Epoch 12/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.7000 - accuracy: 0.7537 - val_loss: 0.7661 - val_accuracy: 0.7352\n",
      "Epoch 13/25\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.6658 - accuracy: 0.7641 - val_loss: 0.7213 - val_accuracy: 0.7527\n",
      "Epoch 14/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.6388 - accuracy: 0.7735 - val_loss: 0.7337 - val_accuracy: 0.7482\n",
      "Epoch 15/25\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.6153 - accuracy: 0.7847 - val_loss: 0.7061 - val_accuracy: 0.7573\n",
      "Epoch 16/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5930 - accuracy: 0.7890 - val_loss: 0.6792 - val_accuracy: 0.7662\n",
      "Epoch 17/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5641 - accuracy: 0.7996 - val_loss: 0.6708 - val_accuracy: 0.7684\n",
      "Epoch 18/25\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.5480 - accuracy: 0.8057 - val_loss: 0.6762 - val_accuracy: 0.7692\n",
      "Epoch 19/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5230 - accuracy: 0.8147 - val_loss: 0.6833 - val_accuracy: 0.7667\n",
      "Epoch 20/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5125 - accuracy: 0.8179 - val_loss: 0.6504 - val_accuracy: 0.7766\n",
      "Epoch 21/25\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.4919 - accuracy: 0.8251 - val_loss: 0.6573 - val_accuracy: 0.7746\n",
      "Epoch 22/25\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4770 - accuracy: 0.8306 - val_loss: 0.6503 - val_accuracy: 0.7772\n",
      "Epoch 23/25\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.4574 - accuracy: 0.8368 - val_loss: 0.6556 - val_accuracy: 0.7797\n",
      "Epoch 24/25\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.4469 - accuracy: 0.8423 - val_loss: 0.6392 - val_accuracy: 0.7811\n",
      "Epoch 25/25\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.4295 - accuracy: 0.8468 - val_loss: 0.6459 - val_accuracy: 0.7823\n",
      "Accuracy: 78.23%\n"
     ]
    }
   ],
   "source": [
    "# Large CNN model for the CIFAR-10 Dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en i5 120.96666666666667\n",
      "tiempo en i7 con docker  49.733333333333334\n",
      "tiempo en i7 41.4\n",
      "ahorro con respecto a docker  0.1675603217158177\n",
      "ahorro con respecto a i5  0.6577569578396252\n",
      "tiempo en windows 10, amd 6300 six-core + nvidia gforce ftx9600 gpu 12.516666666666667\n",
      "ahorro con respecto a i5  0.8965279691375034\n",
      "ahorro con respecto a i7  0.6976650563607085\n"
     ]
    }
   ],
   "source": [
    "ti5 = 120.0 + (58/60)  #minutos\n",
    "print(\"tiempo en i5\", ti5)\n",
    "ti7d = 2984 #segundos\n",
    "print(\"tiempo en i7 con docker \", ti7d/60)\n",
    "ti7 = 2484\n",
    "print(\"tiempo en i7\", ti7/60)\n",
    "print(\"ahorro con respecto a docker \", 1- (ti7 / ti7d))\n",
    "print(\"ahorro con respecto a i5 \", 1- (ti7 / (ti5 * 60)))\n",
    "\n",
    "tw10 = 12 + (31/60) #minutos\n",
    "print(\"tiempo en windows 10, amd 6300 six-core + nvidia gforce ftx9600 gpu\", tw10)\n",
    "print(\"ahorro con respecto a i5 \", 1- (tw10 / (ti5)))\n",
    "print(\"ahorro con respecto a i7 \", 1- (tw10 / (ti7 / 60)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example prints the classification accuracy and loss on the training and test datasets each epoch. The estimate of classification accuracy for the final model is 78.28%, which is nearly 9 points better than our simpler model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions To Improve Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved good results on this very difficult problem, but we are still a good way to achieve world-class results. Below are some ideas that you can try to extend upon the model and improve model performance.\n",
    "\n",
    "* **Train for More Epochs**. Each model was trained for a very small number of epochs, 25. It is common to train large convolutional neural networks for hundreds or thousands of epochs. I would expect that performance gains can be achieved by significantly raising the number of training epochs.\n",
    "* **Image Data Augmentation**. The objects in the image vary in their position. Another boost in model performance can likely be achieved by using some data augmentation. Methods such as standardization and random shifts and horizontal image flips may be beneficial.\n",
    "* **Deeper Network Topology**. The larger network presented is deep, but larger networks could be designed for the problem. This may involve more feature maps closer to the input and perhaps less aggressive pooling. Additionally, standard convolutional network topologies that have been shown useful may be adopted and evaluated on the problem.\n",
    "\n",
    "What accuracy can you achieve on this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"2.xmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"2.xmodel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### improve fitting \n",
    "using the saved model, and iterating more and more each time you run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard --logdir logs/fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ECCNI_~1\\AppData\\Local\\Temp/ipykernel_3856/3816908873.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#tensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard --logdir logs/fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2349\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2350\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2351\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2352\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\magics\\extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Missing module name.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'already loaded'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                     \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard --logdir logs/fit'"
     ]
    }
   ],
   "source": [
    "#tensorboard\n",
    "%load_ext tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint\n",
    "import datetime\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"2.xmodel_b.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "logDir = 'logs/fit/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logDir,histogram_freq=1)\n",
    "callbacks_list = [checkpoint,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "json_file = open('2.xmodel.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loadedModel = tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "#load best weights\n",
    "loadedModel.load_weights('2.xmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,915,114\n",
      "Trainable params: 2,915,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n",
      "782/782 [==============================] - 38s 44ms/step - loss: 0.0773 - accuracy: 0.9743 - val_loss: 0.8864 - val_accuracy: 0.8039\n",
      "Epoch 2/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.1044 - accuracy: 0.9652 - val_loss: 0.8470 - val_accuracy: 0.8060\n",
      "Epoch 3/250\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.1077 - accuracy: 0.9635 - val_loss: 0.7799 - val_accuracy: 0.8132\n",
      "Epoch 4/250\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.1070 - accuracy: 0.9646 - val_loss: 0.8625 - val_accuracy: 0.8063\n",
      "Epoch 5/250\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.1002 - accuracy: 0.9664 - val_loss: 0.8651 - val_accuracy: 0.8059\n",
      "Epoch 6/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.1000 - accuracy: 0.9675 - val_loss: 0.8884 - val_accuracy: 0.8133\n",
      "Epoch 7/250\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0976 - accuracy: 0.9668 - val_loss: 0.8072 - val_accuracy: 0.8032\n",
      "Epoch 8/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0913 - accuracy: 0.9699 - val_loss: 0.8456 - val_accuracy: 0.8101\n",
      "Epoch 9/250\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.0845 - accuracy: 0.9720 - val_loss: 0.9150 - val_accuracy: 0.8013\n",
      "Epoch 10/250\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.0860 - accuracy: 0.9717 - val_loss: 0.8459 - val_accuracy: 0.8118\n",
      "Epoch 11/250\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.0816 - accuracy: 0.9729 - val_loss: 0.8464 - val_accuracy: 0.8074\n",
      "Epoch 12/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0737 - accuracy: 0.9754 - val_loss: 0.8023 - val_accuracy: 0.8170\n",
      "Epoch 13/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0718 - accuracy: 0.9766 - val_loss: 0.8059 - val_accuracy: 0.8169\n",
      "Epoch 14/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0701 - accuracy: 0.9764 - val_loss: 0.8362 - val_accuracy: 0.8166\n",
      "Epoch 15/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.8511 - val_accuracy: 0.8121\n",
      "Epoch 16/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0616 - accuracy: 0.9799 - val_loss: 0.8389 - val_accuracy: 0.8179\n",
      "Epoch 17/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 0.8318 - val_accuracy: 0.8117\n",
      "Epoch 18/250\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 0.8762 - val_accuracy: 0.8135\n",
      "Epoch 19/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.8543 - val_accuracy: 0.8134\n",
      "Epoch 20/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0485 - accuracy: 0.9833 - val_loss: 0.8813 - val_accuracy: 0.8168\n",
      "Epoch 21/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0478 - accuracy: 0.9839 - val_loss: 0.8729 - val_accuracy: 0.8176\n",
      "Epoch 22/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0509 - accuracy: 0.9828 - val_loss: 0.8412 - val_accuracy: 0.8224\n",
      "Epoch 23/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0492 - accuracy: 0.9841 - val_loss: 0.8694 - val_accuracy: 0.8196\n",
      "Epoch 24/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 0.8911 - val_accuracy: 0.8183\n",
      "Epoch 25/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0445 - accuracy: 0.9852 - val_loss: 0.8967 - val_accuracy: 0.8142\n",
      "Epoch 26/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0396 - accuracy: 0.9864 - val_loss: 0.9230 - val_accuracy: 0.8179\n",
      "Epoch 27/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0422 - accuracy: 0.9857 - val_loss: 0.8560 - val_accuracy: 0.8227\n",
      "Epoch 28/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.9013 - val_accuracy: 0.8170\n",
      "Epoch 29/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.9218 - val_accuracy: 0.8190\n",
      "Epoch 30/250\n",
      "782/782 [==============================] - 36s 46ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.8925 - val_accuracy: 0.8202\n",
      "Epoch 31/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 0.8962 - val_accuracy: 0.8253\n",
      "Epoch 32/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.8897 - val_accuracy: 0.8225\n",
      "Epoch 33/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.9399 - val_accuracy: 0.8228\n",
      "Epoch 34/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.9357 - val_accuracy: 0.8189\n",
      "Epoch 35/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 0.9886 - val_accuracy: 0.8196\n",
      "Epoch 36/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.9271 - val_accuracy: 0.8261\n",
      "Epoch 37/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.9318 - val_accuracy: 0.8263\n",
      "Epoch 38/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.9203 - val_accuracy: 0.8244\n",
      "Epoch 39/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.9212 - val_accuracy: 0.8297\n",
      "Epoch 40/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.9372 - val_accuracy: 0.8303\n",
      "Epoch 41/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.9256 - val_accuracy: 0.8328\n",
      "Epoch 42/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.9286 - val_accuracy: 0.8288\n",
      "Epoch 43/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.9825 - val_accuracy: 0.8243\n",
      "Epoch 44/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.9798 - val_accuracy: 0.8235\n",
      "Epoch 45/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.9707 - val_accuracy: 0.8256\n",
      "Epoch 46/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.9284 - val_accuracy: 0.8279\n",
      "Epoch 47/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.9658 - val_accuracy: 0.8273\n",
      "Epoch 48/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.9917 - val_accuracy: 0.8287\n",
      "Epoch 49/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.9681 - val_accuracy: 0.8298\n",
      "Epoch 50/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.9687 - val_accuracy: 0.8284\n",
      "Epoch 51/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.9683 - val_accuracy: 0.8293\n",
      "Epoch 52/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.9453 - val_accuracy: 0.8285\n",
      "Epoch 53/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.9200 - val_accuracy: 0.8310\n",
      "Epoch 54/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.9801 - val_accuracy: 0.8283\n",
      "Epoch 55/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.9848 - val_accuracy: 0.8294\n",
      "Epoch 56/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.9388 - val_accuracy: 0.8311\n",
      "Epoch 57/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.9823 - val_accuracy: 0.8311\n",
      "Epoch 58/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 1.0061 - val_accuracy: 0.8328\n",
      "Epoch 59/250\n",
      "782/782 [==============================] - 32s 42ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.9794 - val_accuracy: 0.8325\n",
      "Epoch 60/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.9786 - val_accuracy: 0.8307\n",
      "Epoch 61/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 1.0085 - val_accuracy: 0.8289\n",
      "Epoch 62/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.9924 - val_accuracy: 0.8311\n",
      "Epoch 63/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 1.0440 - val_accuracy: 0.8292\n",
      "Epoch 64/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 1.0219 - val_accuracy: 0.8317\n",
      "Epoch 65/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 1.0132 - val_accuracy: 0.8276\n",
      "Epoch 66/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.0426 - val_accuracy: 0.8257\n",
      "Epoch 67/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 1.0008 - val_accuracy: 0.8325\n",
      "Epoch 68/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 1.0418 - val_accuracy: 0.8252\n",
      "Epoch 69/250\n",
      "782/782 [==============================] - 32s 42ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 1.0593 - val_accuracy: 0.8290\n",
      "Epoch 70/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 1.0239 - val_accuracy: 0.8323\n",
      "Epoch 71/250\n",
      "782/782 [==============================] - 32s 42ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.0481 - val_accuracy: 0.8276\n",
      "Epoch 72/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 1.0431 - val_accuracy: 0.8307\n",
      "Epoch 73/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 1.0083 - val_accuracy: 0.8291\n",
      "Epoch 74/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 1.0033 - val_accuracy: 0.8323\n",
      "Epoch 75/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.9972 - val_accuracy: 0.8333\n",
      "Epoch 76/250\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.9979 - val_accuracy: 0.8303\n",
      "Epoch 77/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.9884 - val_accuracy: 0.8275\n",
      "Epoch 78/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 1.0265 - val_accuracy: 0.8291\n",
      "Epoch 79/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.9962 - val_accuracy: 0.8319\n",
      "Epoch 80/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 1.0134 - val_accuracy: 0.8319\n",
      "Epoch 81/250\n",
      "782/782 [==============================] - 35s 44ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 1.0431 - val_accuracy: 0.8298\n",
      "Epoch 82/250\n",
      "782/782 [==============================] - 35s 44ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.0380 - val_accuracy: 0.8320\n",
      "Epoch 83/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.0677 - val_accuracy: 0.8294\n",
      "Epoch 84/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 1.0469 - val_accuracy: 0.8302\n",
      "Epoch 85/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.0606 - val_accuracy: 0.8282\n",
      "Epoch 86/250\n",
      "782/782 [==============================] - 35s 44ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 1.0372 - val_accuracy: 0.8286\n",
      "Epoch 87/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 1.0319 - val_accuracy: 0.8279\n",
      "Epoch 88/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.0329 - val_accuracy: 0.8329\n",
      "Epoch 89/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.0733 - val_accuracy: 0.8279\n",
      "Epoch 90/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.0693 - val_accuracy: 0.8336\n",
      "Epoch 91/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.0406 - val_accuracy: 0.8322\n",
      "Epoch 92/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.0113 - val_accuracy: 0.8288\n",
      "Epoch 93/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 1.0171 - val_accuracy: 0.8336\n",
      "Epoch 94/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.0534 - val_accuracy: 0.8342\n",
      "Epoch 95/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.0570 - val_accuracy: 0.8330\n",
      "Epoch 96/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.0428 - val_accuracy: 0.8314\n",
      "Epoch 97/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.0391 - val_accuracy: 0.8362\n",
      "Epoch 98/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.0492 - val_accuracy: 0.8337\n",
      "Epoch 99/250\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.0439 - val_accuracy: 0.8337\n",
      "Epoch 100/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.0594 - val_accuracy: 0.8324\n",
      "Epoch 101/250\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.0534 - val_accuracy: 0.8355\n",
      "Epoch 102/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.0784 - val_accuracy: 0.8334\n",
      "Epoch 103/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 1.0566 - val_accuracy: 0.8370\n",
      "Epoch 104/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.0579 - val_accuracy: 0.8339\n",
      "Epoch 105/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 1.0386 - val_accuracy: 0.8361\n",
      "Epoch 106/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.0568 - val_accuracy: 0.8371\n",
      "Epoch 107/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.0532 - val_accuracy: 0.8353\n",
      "Epoch 108/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 1.0468 - val_accuracy: 0.8324\n",
      "Epoch 109/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.0448 - val_accuracy: 0.8357\n",
      "Epoch 110/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 1.0493 - val_accuracy: 0.8348\n",
      "Epoch 111/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 1.0915 - val_accuracy: 0.8267\n",
      "Epoch 112/250\n",
      "782/782 [==============================] - 26s 33ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.0700 - val_accuracy: 0.8281\n",
      "Epoch 113/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 1.0426 - val_accuracy: 0.8337\n",
      "Epoch 114/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.0612 - val_accuracy: 0.8340\n",
      "Epoch 115/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 1.0554 - val_accuracy: 0.8308\n",
      "Epoch 116/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 1.0636 - val_accuracy: 0.8350\n",
      "Epoch 117/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 1.0537 - val_accuracy: 0.8333\n",
      "Epoch 118/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 1.0423 - val_accuracy: 0.8306\n",
      "Epoch 119/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 1.0693 - val_accuracy: 0.8333\n",
      "Epoch 120/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.0656 - val_accuracy: 0.8355\n",
      "Epoch 121/250\n",
      "782/782 [==============================] - 35s 44ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.0487 - val_accuracy: 0.8350\n",
      "Epoch 122/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.0771 - val_accuracy: 0.8318\n",
      "Epoch 123/250\n",
      "782/782 [==============================] - 36s 46ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.0415 - val_accuracy: 0.8322\n",
      "Epoch 124/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 1.0608 - val_accuracy: 0.8348\n",
      "Epoch 125/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.0588 - val_accuracy: 0.8328\n",
      "Epoch 126/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 1.0762 - val_accuracy: 0.8362\n",
      "Epoch 127/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 1.1061 - val_accuracy: 0.8306\n",
      "Epoch 128/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.0577 - val_accuracy: 0.8345\n",
      "Epoch 129/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.0487 - val_accuracy: 0.8353\n",
      "Epoch 130/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.0669 - val_accuracy: 0.8339\n",
      "Epoch 131/250\n",
      "782/782 [==============================] - 33s 43ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.0740 - val_accuracy: 0.8326\n",
      "Epoch 132/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 1.0673 - val_accuracy: 0.8330\n",
      "Epoch 133/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 1.0616 - val_accuracy: 0.8332\n",
      "Epoch 134/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 1.0945 - val_accuracy: 0.8341\n",
      "Epoch 135/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.0683 - val_accuracy: 0.8364\n",
      "Epoch 136/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 1.0650 - val_accuracy: 0.8352\n",
      "Epoch 137/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 1.0637 - val_accuracy: 0.8347\n",
      "Epoch 138/250\n",
      "782/782 [==============================] - 35s 44ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 1.0539 - val_accuracy: 0.8356\n",
      "Epoch 139/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 1.0639 - val_accuracy: 0.8360\n",
      "Epoch 140/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.0764 - val_accuracy: 0.8363\n",
      "Epoch 141/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.0816 - val_accuracy: 0.8375\n",
      "Epoch 142/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 1.0798 - val_accuracy: 0.8353\n",
      "Epoch 143/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 1.0844 - val_accuracy: 0.8349\n",
      "Epoch 144/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 1.0707 - val_accuracy: 0.8325\n",
      "Epoch 145/250\n",
      "782/782 [==============================] - 35s 44ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.0882 - val_accuracy: 0.8345\n",
      "Epoch 146/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.0891 - val_accuracy: 0.8346\n",
      "Epoch 147/250\n",
      "782/782 [==============================] - 35s 45ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.0852 - val_accuracy: 0.8353\n",
      "Epoch 148/250\n",
      "782/782 [==============================] - 32s 42ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.0840 - val_accuracy: 0.8358\n",
      "Epoch 149/250\n",
      "782/782 [==============================] - 36s 45ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 1.1023 - val_accuracy: 0.8348\n",
      "Epoch 150/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.0722 - val_accuracy: 0.8359\n",
      "Epoch 151/250\n",
      "782/782 [==============================] - 34s 44ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.0628 - val_accuracy: 0.8355\n",
      "Epoch 152/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 1.0814 - val_accuracy: 0.8355\n",
      "Epoch 153/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 1.0782 - val_accuracy: 0.8343\n",
      "Epoch 154/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 1.0561 - val_accuracy: 0.8360\n",
      "Epoch 155/250\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 1.0828 - val_accuracy: 0.8378\n",
      "Epoch 156/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 1.0779 - val_accuracy: 0.8374\n",
      "Epoch 157/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 1.1061 - val_accuracy: 0.8353\n",
      "Epoch 158/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 1.1005 - val_accuracy: 0.8356\n",
      "Epoch 159/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 1.0895 - val_accuracy: 0.8365\n",
      "Epoch 160/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 1.0975 - val_accuracy: 0.8362\n",
      "Epoch 161/250\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.0905 - val_accuracy: 0.8377\n",
      "Epoch 162/250\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 1.0952 - val_accuracy: 0.8364\n",
      "Epoch 163/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 1.0715 - val_accuracy: 0.8345\n",
      "Epoch 164/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 1.0878 - val_accuracy: 0.8343\n",
      "Epoch 165/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 1.0965 - val_accuracy: 0.8365\n",
      "Epoch 166/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 1.1104 - val_accuracy: 0.8358\n",
      "Epoch 167/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 1.0879 - val_accuracy: 0.8352\n",
      "Epoch 168/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.0829 - val_accuracy: 0.8352\n",
      "Epoch 169/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.1273 - val_accuracy: 0.8370\n",
      "Epoch 170/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 1.1233 - val_accuracy: 0.8358\n",
      "Epoch 171/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 1.1281 - val_accuracy: 0.8351\n",
      "Epoch 172/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.1163 - val_accuracy: 0.8372\n",
      "Epoch 173/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.1087 - val_accuracy: 0.8361\n",
      "Epoch 174/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.1114 - val_accuracy: 0.8346\n",
      "Epoch 175/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.1106 - val_accuracy: 0.8349\n",
      "Epoch 176/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 1.0983 - val_accuracy: 0.8347\n",
      "Epoch 177/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.1109 - val_accuracy: 0.8344\n",
      "Epoch 178/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.1186 - val_accuracy: 0.8350\n",
      "Epoch 179/250\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 1.1073 - val_accuracy: 0.8372\n",
      "Epoch 180/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.1069 - val_accuracy: 0.8372\n",
      "Epoch 181/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.0984 - val_accuracy: 0.8358\n",
      "Epoch 182/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 1.0861 - val_accuracy: 0.8364\n",
      "Epoch 183/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 1.0773 - val_accuracy: 0.8375\n",
      "Epoch 184/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 1.0977 - val_accuracy: 0.8369\n",
      "Epoch 185/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.1224 - val_accuracy: 0.8352\n",
      "Epoch 186/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 1.1082 - val_accuracy: 0.8370\n",
      "Epoch 187/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.1091 - val_accuracy: 0.8359\n",
      "Epoch 188/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.1069 - val_accuracy: 0.8378\n",
      "Epoch 189/250\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 1.1224 - val_accuracy: 0.8346\n",
      "Epoch 190/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.1150 - val_accuracy: 0.8347\n",
      "Epoch 191/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 1.1002 - val_accuracy: 0.8362\n",
      "Epoch 192/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 1.1100 - val_accuracy: 0.8352\n",
      "Epoch 193/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.1105 - val_accuracy: 0.8348\n",
      "Epoch 194/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.1253 - val_accuracy: 0.8367\n",
      "Epoch 195/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 1.1120 - val_accuracy: 0.8352\n",
      "Epoch 196/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.1177 - val_accuracy: 0.8345\n",
      "Epoch 197/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 1.1372 - val_accuracy: 0.8365\n",
      "Epoch 198/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.1092 - val_accuracy: 0.8350\n",
      "Epoch 199/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.1160 - val_accuracy: 0.8347\n",
      "Epoch 200/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.0849 - val_accuracy: 0.8390\n",
      "Epoch 201/250\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.1022 - val_accuracy: 0.8371\n",
      "Epoch 202/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.1031 - val_accuracy: 0.8374\n",
      "Epoch 203/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.1061 - val_accuracy: 0.8345\n",
      "Epoch 204/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.1000 - val_accuracy: 0.8363\n",
      "Epoch 205/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.0959 - val_accuracy: 0.8379\n",
      "Epoch 206/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 1.0997 - val_accuracy: 0.8367\n",
      "Epoch 207/250\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 1.1065 - val_accuracy: 0.8374\n",
      "Epoch 208/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.1245 - val_accuracy: 0.8352\n",
      "Epoch 209/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 1.1033 - val_accuracy: 0.8365\n",
      "Epoch 210/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.1155 - val_accuracy: 0.8345\n",
      "Epoch 211/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.1139 - val_accuracy: 0.8356\n",
      "Epoch 212/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 1.1192 - val_accuracy: 0.8356\n",
      "Epoch 213/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 1.1156 - val_accuracy: 0.8379\n",
      "Epoch 214/250\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.1085 - val_accuracy: 0.8365\n",
      "Epoch 215/250\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 1.0926 - val_accuracy: 0.8371\n",
      "Epoch 216/250\n",
      "782/782 [==============================] - 32s 42ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.1067 - val_accuracy: 0.8367\n",
      "Epoch 217/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 1.1160 - val_accuracy: 0.8372\n",
      "Epoch 218/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 1.1190 - val_accuracy: 0.8369\n",
      "Epoch 219/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 1.1039 - val_accuracy: 0.8387\n",
      "Epoch 220/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.1118 - val_accuracy: 0.8371\n",
      "Epoch 221/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.1004 - val_accuracy: 0.8392\n",
      "Epoch 222/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 1.0982 - val_accuracy: 0.8371\n",
      "Epoch 223/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 1.1009 - val_accuracy: 0.8376\n",
      "Epoch 224/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.1079 - val_accuracy: 0.8377\n",
      "Epoch 225/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.0962 - val_accuracy: 0.8389\n",
      "Epoch 226/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.1133 - val_accuracy: 0.8363\n",
      "Epoch 227/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.1155 - val_accuracy: 0.8364\n",
      "Epoch 228/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.1097 - val_accuracy: 0.8355\n",
      "Epoch 229/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 1.1031 - val_accuracy: 0.8393\n",
      "Epoch 230/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 1.1013 - val_accuracy: 0.8396\n",
      "Epoch 231/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.1024 - val_accuracy: 0.8382\n",
      "Epoch 232/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.1028 - val_accuracy: 0.8365\n",
      "Epoch 233/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.1079 - val_accuracy: 0.8375\n",
      "Epoch 234/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.1098 - val_accuracy: 0.8368\n",
      "Epoch 235/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 1.1120 - val_accuracy: 0.8385\n",
      "Epoch 236/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.1056 - val_accuracy: 0.8383\n",
      "Epoch 237/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.1147 - val_accuracy: 0.8387\n",
      "Epoch 238/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 1.1205 - val_accuracy: 0.8370\n",
      "Epoch 239/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 1.1051 - val_accuracy: 0.8394\n",
      "Epoch 240/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.1094 - val_accuracy: 0.8387\n",
      "Epoch 241/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.1288 - val_accuracy: 0.8398\n",
      "Epoch 242/250\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 1.1241 - val_accuracy: 0.8379\n",
      "Epoch 243/250\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.1438 - val_accuracy: 0.8362\n",
      "Epoch 244/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.1394 - val_accuracy: 0.8376\n",
      "Epoch 245/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 1.1317 - val_accuracy: 0.8369\n",
      "Epoch 246/250\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 1.1117 - val_accuracy: 0.8406\n",
      "Epoch 247/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.1099 - val_accuracy: 0.8381\n",
      "Epoch 248/250\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 1.1092 - val_accuracy: 0.8363\n",
      "Epoch 249/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.1041 - val_accuracy: 0.8390\n",
      "Epoch 250/250\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 1.1124 - val_accuracy: 0.8375\n",
      "Accuracy: 83.75%\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "epochs = 250\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "loadedModel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "loadedModel.summary()\n",
    "\n",
    "# Fit the model\n",
    "loadedModel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64, callbacks=callbacks_list)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = loadedModel.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, you discovered how to create deep learning models in Keras for object recognition in photographs. After working through this tutorial, you learned:\n",
    "\n",
    "* About the CIFAR-10 dataset and how to load it in Keras and plot ad hoc examples from the dataset.\n",
    "* How to train and evaluate a simple Convolutional Neural Network on the problem.\n",
    "* How to expand a simple convolutional neural network into a deep convolutional neural network to boost performance on the difficult problem.\n",
    "* How to use data augmentation to get a further boost on the difficult object recognition problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49ff9a1d55cbad36b515c3ded8837e12145fab330794be4b4ac6e95d3772d975"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
